{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "yG_n40gFzf9s",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOURCE TEXT LOADING\n",
    "- loading .txt\n",
    "- printing the beginning, number of characters, number of unique characters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aavnuByVymwK",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE  FELLOWSHIP \n",
      "OF  THE  RING \n",
      "\n",
      "\n",
      "BEING  THE  FIRST  PART \n",
      "OF \n",
      "\n",
      "The  Lord  of  the  Rings \n",
      "\n",
      "\n",
      "BOOK  ONE \n",
      "\n",
      "\n",
      "Chapter  I \n",
      "\n",
      "\n",
      "A  LONG-EXPECTED  PARTY \n",
      "\n",
      "\n",
      "When  Mr.  Bilbo  Baggins  of  Bag  End  announced  that  he \n",
      "would  shortly  be  celebrating  his  eleventy-first  birthday  with \n",
      "a  party  of  special\n"
     ]
    }
   ],
   "source": [
    "with open(\"sources/ring.txt\", \"r\") as f:\n",
    "    source = f.read()\n",
    "print(source[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "Duhg9NrUymwO",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145534 characters\n"
     ]
    }
   ],
   "source": [
    "print ('{} characters'.format(len(source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "IlCgQBRVymwR",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(source))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "IalZLbvOzf-F",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45 33 30 ...  1  0  0]\n"
     ]
    }
   ],
   "source": [
    "# unique characters to indices mapping\n",
    "char2index = {u:i for i, u in enumerate(vocab)}\n",
    "index2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2index[c] for c in source])\n",
    "\n",
    "print(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "l1VKcQHcymwb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE  FELLOWSH' -- characters mapped to int -- > [45 33 30  1  1 31 30 37 37 40 48 44 33]\n"
     ]
    }
   ],
   "source": [
    "print ('{} -- characters mapped to int -- > {}'.format(repr(source[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET PREPROCESSING\n",
    "- character to index mapping and converting text to numerical representation\n",
    "- defining max input sequence length\n",
    "- creating TensorFlow Dataset from the source\n",
    "- creating batches from dataset\n",
    "- input-target split function (:-1 is input, and last element is expected value)\n",
    "- applying input-target split function to each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "0UHJDA39zf-O",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "H\n",
      "E\n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(source)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(index2char[i.numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "l4hkDU3i7ozi",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE  FELLOWSHIP \\nOF  THE  RING \\n\\n\\nBEING  THE  FIRST  PART \\nOF \\n\\nThe  Lord  of  the  Rings \\n\\n\\nBOOK  ON'\n",
      "'E \\n\\n\\nChapter  I \\n\\n\\nA  LONG-EXPECTED  PARTY \\n\\n\\nWhen  Mr.  Bilbo  Baggins  of  Bag  End  announced  tha'\n",
      "'t  he \\nwould  shortly  be  celebrating  his  eleventy-first  birthday  with \\na  party  of  special  m'\n",
      "'agnificence,  there  was  much  talk  and \\nexcitement  in  Hobbiton. \\n\\nBilbo  was  very  rich  and  v'\n",
      "'ery  peculiar,  and  had  been  the \\nwonder  of  the  Shire  for  sixty  years,  ever  since  his  re'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(index2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "9NGu-FkO_kYU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS\n",
    "- training parameters & data shuffling\n",
    "- model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "p2pGotuNzf-S",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(2048, 100), dtype=tf.int64, name=None), TensorSpec(shape=(2048, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 2048\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "zHT8cLh7EAsg",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 300 #256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units1 = 256\n",
    "rnn_units2 = 256\n",
    "rnn_units=[rnn_units1, rnn_units2]\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING MODEL\n",
    "- GRU, LSTM, RNN, with Conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "MtCrdfzEI2N0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ORIGINAL GRU\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units1,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.GRU(rnn_units2,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "wwsrpOik5zhv",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._iterations\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._learning_rate\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.13\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.14\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.15\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.16\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.17\n",
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.18\n"
     ]
    }
   ],
   "source": [
    "model = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "vPGmAAXmVLGC",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (2048, None, 300)         26400     \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (2048, None, 256)         428544    \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (2048, None, 256)         394752    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (2048, None, 88)          22616     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 872,312\n",
      "Trainable params: 872,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAINING\n",
    "- optimizer & loss function declaration\n",
    "- compilation\n",
    "- epochs number\n",
    "- launching the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "4HrXTACTdzY-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "DDl1_Een6rL0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "W6fWTriUZP-n",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints_GRU'        # TODO: remember to choose proper directory\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7yGBE2zxMMHs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK-hmKjYVoll",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 37s 6s/step - loss: 4.3181 - accuracy: 0.2425\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 28s 5s/step - loss: 3.4528 - accuracy: 0.3009\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 27s 5s/step - loss: 3.0775 - accuracy: 0.3009\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 27s 5s/step - loss: 2.9523 - accuracy: 0.3008\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.9011 - accuracy: 0.3007\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.8704 - accuracy: 0.3008\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.8404 - accuracy: 0.3008\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.8031 - accuracy: 0.3007\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.7495 - accuracy: 0.3004\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.6715 - accuracy: 0.3168\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.5903 - accuracy: 0.3352\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.5042 - accuracy: 0.3535\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 25s 5s/step - loss: 2.4173 - accuracy: 0.3801\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 29s 6s/step - loss: 2.3312 - accuracy: 0.3959\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 30s 6s/step - loss: 2.2547 - accuracy: 0.4079\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 27s 5s/step - loss: 2.1971 - accuracy: 0.4105\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.1483 - accuracy: 0.4189\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.1091 - accuracy: 0.4248\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.0762 - accuracy: 0.4271\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.0466 - accuracy: 0.4289\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 2.0220 - accuracy: 0.4296\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.9960 - accuracy: 0.4336\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.9712 - accuracy: 0.4409\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.9478 - accuracy: 0.4479\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 24s 4s/step - loss: 1.9257 - accuracy: 0.4542\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.9049 - accuracy: 0.4593\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.8850 - accuracy: 0.4644\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.8660 - accuracy: 0.4711\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.8468 - accuracy: 0.4767\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.8294 - accuracy: 0.4816\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.8101 - accuracy: 0.4872\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.7936 - accuracy: 0.4914\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.7757 - accuracy: 0.4966\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.7588 - accuracy: 0.5014\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.7406 - accuracy: 0.5073\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.7237 - accuracy: 0.5101\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.7087 - accuracy: 0.5136\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 26s 5s/step - loss: 1.6933 - accuracy: 0.5174\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.6761 - accuracy: 0.5219\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.6625 - accuracy: 0.5250\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.6471 - accuracy: 0.5282\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.6320 - accuracy: 0.5326\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.6186 - accuracy: 0.5361\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.6048 - accuracy: 0.5397\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5923 - accuracy: 0.5431\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5798 - accuracy: 0.5461\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5664 - accuracy: 0.5503\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5544 - accuracy: 0.5533\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5431 - accuracy: 0.5566\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5313 - accuracy: 0.5598\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.5192 - accuracy: 0.5632\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.5076 - accuracy: 0.5664\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.4977 - accuracy: 0.5688\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.4869 - accuracy: 0.5715\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.4780 - accuracy: 0.5734\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.4673 - accuracy: 0.5764\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.4581 - accuracy: 0.5782\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.4487 - accuracy: 0.5803\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 30s 5s/step - loss: 1.4392 - accuracy: 0.5825\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 27s 5s/step - loss: 1.4315 - accuracy: 0.5845\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.4230 - accuracy: 0.5869\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.4126 - accuracy: 0.5897\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.4048 - accuracy: 0.5914\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3966 - accuracy: 0.5935\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3886 - accuracy: 0.5958\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3799 - accuracy: 0.5978\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3734 - accuracy: 0.5995\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3647 - accuracy: 0.6018\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3594 - accuracy: 0.6031\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3510 - accuracy: 0.6052\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3446 - accuracy: 0.6069\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.3388 - accuracy: 0.6086\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 32s 7s/step - loss: 1.3318 - accuracy: 0.6103\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 27s 5s/step - loss: 1.3254 - accuracy: 0.6117\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 28s 5s/step - loss: 1.3195 - accuracy: 0.6134\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.3137 - accuracy: 0.6150\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 26s 5s/step - loss: 1.3069 - accuracy: 0.6167\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 29s 6s/step - loss: 1.3016 - accuracy: 0.6182\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.2967 - accuracy: 0.6197\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.2912 - accuracy: 0.6214\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 25s 5s/step - loss: 1.2861 - accuracy: 0.6227\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2802 - accuracy: 0.6239\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2760 - accuracy: 0.6253\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2707 - accuracy: 0.6270\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2658 - accuracy: 0.6282\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2621 - accuracy: 0.6291\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2577 - accuracy: 0.6305\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2543 - accuracy: 0.6312\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2485 - accuracy: 0.6327\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 21s 4s/step - loss: 1.2448 - accuracy: 0.6335\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2416 - accuracy: 0.6346\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2368 - accuracy: 0.6358\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2318 - accuracy: 0.6371\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2290 - accuracy: 0.6377\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.2264 - accuracy: 0.6386\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2220 - accuracy: 0.6396\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.2181 - accuracy: 0.6406\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 22s 4s/step - loss: 1.2152 - accuracy: 0.6412\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.2120 - accuracy: 0.6420\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.2096 - accuracy: 0.6426\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.2045 - accuracy: 0.6440\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.2021 - accuracy: 0.6444\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1990 - accuracy: 0.6453\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1958 - accuracy: 0.6461\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1932 - accuracy: 0.6467\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1898 - accuracy: 0.6476\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1878 - accuracy: 0.6483\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 26s 5s/step - loss: 1.1845 - accuracy: 0.6489\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1821 - accuracy: 0.6499\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1800 - accuracy: 0.6502\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1741 - accuracy: 0.6516\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 23s 5s/step - loss: 1.1720 - accuracy: 0.6522\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1716 - accuracy: 0.6523\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1691 - accuracy: 0.6529\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 24s 4s/step - loss: 1.1658 - accuracy: 0.6538\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1639 - accuracy: 0.6538\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1620 - accuracy: 0.6546\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 24s 5s/step - loss: 1.1600 - accuracy: 0.6550\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1574 - accuracy: 0.6559\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1529 - accuracy: 0.6570\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 23s 4s/step - loss: 1.1516 - accuracy: 0.6572\n",
      "Epoch 122/200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS\n",
    "- bulding the model and applying saved weights\n",
    "- text generation function\n",
    "- generate text based on the provided beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zk2WJ2-XjkGz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latest_check= tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "LycQ-ot_jjyu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(latest_check)\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "71xa6jnYVrAN",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (1, None, 300)            26400     \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (1, None, 256)            428544    \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (1, None, 256)            394752    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, None, 88)             22616     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 872,312\n",
      "Trainable params: 872,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WvuwZBX5Ogfd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "\n",
    "  num_generate = 1000\n",
    "  input_eval = [char2index[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "  scaling = 0.5\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "      predictions = predictions / scaling\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      text_generated.append(index2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry killed Ron  e  e  s e   a       e  eii                           a h    e      ra    a h    e              e se t ea r       i  n   aa   e n              d       i   d   l       e ie       s  r         r             h  \n",
      "e   t    am          ld  a      l   s n  gde    t n ae        w   ad n e i s  ss         s  d l       lee i   a  s  stt         a  oi   h s e     e srgt  ae  o  a    e      d  ,edr     n o  inm   enia ai  a r s t  dh                              an    d   u a    i  hi    e      wo      r              ss   o t   a a u selelndas \n",
      " rn    tr     a             n e e       pt  \n",
      "  n     r l        o a  etdh s      le   on     il     e s ru e e     l n   l  as na     ll y    he ee          a   es  i   ta  h             a  d      n  m    le\n",
      "e   i d   d    r d          n a  rn   e  u     s n   e       i  o  ra tn     h d t  a  h        r    e o         n       a   e amor es e i      ln  a \n",
      " o  ms h   e    n   t i e      a          w      \n",
      "e      a  s  ed         l   \n",
      "e\n",
      "     n s  a u    e d \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Harry killed Ron \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchaster Uniter just lost the war on Anfield fighting m  ad  ertw       s      ud e  s  h  in  r        t      e  a    hag    e      e or    r    et    a i e        l  e                  e er     l y     t  t       i  r  o          att       ewas      n     e      n  h w a o       n  t    ,h      m    ae            nsa      . d     d     y  e      h  r n  e     a e  yild   s  ie   d   edd neg   l rae a  te   a i     se a       h       ede a l     eh  a  anr  d eh   e    ee   nlea d   o      i         e   n dt   s      at  e  emi   e  s          tfe      r  d sh       so    n   ae e            dett            e s  es   \n",
      "  r    a   o e   i   i           e  n n d sdt  oe   i         o      f        i e      s     ie i m         iops  e  t      s    \n",
      "  \n",
      " e      wt   u  e          a\n",
      "  l os    d an     a    r   r d e  a n r  e   si     es rl uee de      n   s     i e id e     e      it m   el         n  re          n m   n   se   a s   nn  r  ye  n e  c  y         e    t i.  y.    w  e  i t  hoe   s r nwl      n   eeo d  e e     sh  t  nn  e  \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Manchaster Uniter just lost the war on Anfield fighting\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cross_entropy_loss(model, test_sequences):\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for sequence in test_sequences:\n",
    "        input_seq = sequence[:-1]\n",
    "        target_seq = sequence[1:]\n",
    "        \n",
    "        input_seq = tf.expand_dims(input_seq, 0)\n",
    "        \n",
    "        predictions = model(input_seq)\n",
    "        \n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(target_seq, predictions[0], from_logits=True)\n",
    "        \n",
    "        total_loss += tf.reduce_sum(loss).numpy()\n",
    "        total_steps += len(target_seq)\n",
    "    \n",
    "    avg_loss = total_loss / total_steps\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutaj można załadować inną część tolkiena albo hobbita\n",
    "first_10_sequences = list(sequences.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.331626892089844"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss = calculate_cross_entropy_loss(model, first_10_sequences)\n",
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.892457089374666"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity = np.exp(avg_loss)\n",
    "perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
