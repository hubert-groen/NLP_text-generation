{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "yG_n40gFzf9s",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 22:47:52.160420: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 22:47:52.214955: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-26 22:47:52.215810: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-26 22:47:53.243534: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SOURCE TEXT LOADING\n",
    "- loading .txt\n",
    "- printing the beginning, number of characters, number of unique characters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aavnuByVymwK",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE  FELLOWSHIP \n",
      "OF  THE  RING \n",
      "\n",
      "\n",
      "BEING  THE  FIRST  PART \n",
      "OF \n",
      "\n",
      "The  Lord  of  the  Rings \n",
      "\n",
      "\n",
      "BOOK  ONE \n",
      "\n",
      "\n",
      "Chapter  I \n",
      "\n",
      "\n",
      "A  LONG-EXPECTED  PARTY \n",
      "\n",
      "\n",
      "When  Mr.  Bilbo  Baggins  of  Bag  End  announced  that  he \n",
      "would  shortly  be  celebrating  his  eleventy-first  birthday  with \n",
      "a  party  of  special\n"
     ]
    }
   ],
   "source": [
    "with open(\"ring.txt\", \"r\") as f:\n",
    "    source = f.read()\n",
    "print(source[:300])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Duhg9NrUymwO",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145534 characters\n"
     ]
    }
   ],
   "source": [
    "print ('{} characters'.format(len(source)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IlCgQBRVymwR",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(source))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "IalZLbvOzf-F",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45 33 30 ...  1  0  0]\n"
     ]
    }
   ],
   "source": [
    "# unique characters to indices mapping\n",
    "char2index = {u:i for i, u in enumerate(vocab)}\n",
    "index2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2index[c] for c in source])\n",
    "\n",
    "print(text_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "l1VKcQHcymwb",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE  FELLOWSH' -- characters mapped to int -- > [45 33 30  1  1 31 30 37 37 40 48 44 33]\n"
     ]
    }
   ],
   "source": [
    "print ('{} -- characters mapped to int -- > {}'.format(repr(source[:13]), text_as_int[:13]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET PREPROCESSING\n",
    "- character to index mapping and converting text to numerical representation\n",
    "- defining max input sequence length\n",
    "- creating TensorFlow Dataset from the source\n",
    "- creating batches from dataset\n",
    "- input-target split function (:-1 is input, and last element is expected value)\n",
    "- applying input-target split function to each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0UHJDA39zf-O",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "H\n",
      "E\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 22:47:55.672876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-26 22:47:55.712900: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-12-26 22:47:55.754564: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1145534]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(source)//(seq_length+1)\n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(index2char[i.numpy()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "l4hkDU3i7ozi",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 22:47:55.909058: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1145534]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'THE  FELLOWSHIP \\nOF  THE  RING \\n\\n\\nBEING  THE  FIRST  PART \\nOF \\n\\nThe  Lord  of  the  Rings \\n\\n\\nBOOK  ON'\n",
      "'E \\n\\n\\nChapter  I \\n\\n\\nA  LONG-EXPECTED  PARTY \\n\\n\\nWhen  Mr.  Bilbo  Baggins  of  Bag  End  announced  tha'\n",
      "'t  he \\nwould  shortly  be  celebrating  his  eleventy-first  birthday  with \\na  party  of  special  m'\n",
      "'agnificence,  there  was  much  talk  and \\nexcitement  in  Hobbiton. \\n\\nBilbo  was  very  rich  and  v'\n",
      "'ery  peculiar,  and  had  been  the \\nwonder  of  the  Shire  for  sixty  years,  ever  since  his  re'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "  print(repr(''.join(index2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9NGu-FkO_kYU",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PARAMETERS\n",
    "- training parameters & data shuffling\n",
    "- model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "p2pGotuNzf-S",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zHT8cLh7EAsg",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 300 #256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units1 = 1024\n",
    "rnn_units2 = 1024\n",
    "rnn_units=[rnn_units1, rnn_units2]\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING MODEL\n",
    "- GRU, LSTM, RNN, with Conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "MtCrdfzEI2N0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # ORIGINAL GRU\n",
    "# def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "#   model = tf.keras.Sequential([\n",
    "#     tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "#                               batch_input_shape=[batch_size, None]),\n",
    "#     tf.keras.layers.GRU(rnn_units1,\n",
    "#                         return_sequences=True,\n",
    "#                         stateful=True,\n",
    "#                         recurrent_initializer='glorot_uniform'),\n",
    "#     tf.keras.layers.GRU(rnn_units2,\n",
    "#                         return_sequences=True,\n",
    "#                         stateful=True,\n",
    "#                         recurrent_initializer='glorot_uniform'),\n",
    "#     tf.keras.layers.Dense(vocab_size)\n",
    "#   ])\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # LSTM\n",
    "# def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "#                                   batch_input_shape=[batch_size, None]),\n",
    "#         tf.keras.layers.LSTM(rnn_units1,\n",
    "#                              return_sequences=True,\n",
    "#                              stateful=True,\n",
    "#                              recurrent_initializer='glorot_uniform'),\n",
    "#         tf.keras.layers.LSTM(rnn_units2,\n",
    "#                              return_sequences=True,\n",
    "#                              stateful=True,\n",
    "#                              recurrent_initializer='glorot_uniform'),\n",
    "#         tf.keras.layers.Dense(vocab_size)\n",
    "#     ])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.SimpleRNN(rnn_units1,\n",
    "                                  return_sequences=True,\n",
    "                                  stateful=True,\n",
    "                                  recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.SimpleRNN(rnn_units2,\n",
    "                                  return_sequences=True,\n",
    "                                  stateful=True,\n",
    "                                  recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dodanie Conv1\n",
    "# def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Embedding(vocab_size, embedding_dim, \n",
    "#                                   batch_input_shape=[batch_size, None]),\n",
    "#         tf.keras.layers.Conv1D(filters=128, \n",
    "#                                kernel_size=5, \n",
    "#                                activation='relu', \n",
    "#                                padding='same'),\n",
    "#         tf.keras.layers.GRU(rnn_units1,\n",
    "#                             return_sequences=True,\n",
    "#                             stateful=True,\n",
    "#                             recurrent_initializer='glorot_uniform'),\n",
    "#         tf.keras.layers.GRU(rnn_units2,\n",
    "#                             return_sequences=True,\n",
    "#                             stateful=True,\n",
    "#                             recurrent_initializer='glorot_uniform'),\n",
    "#         tf.keras.layers.Dense(vocab_size)\n",
    "#     ])\n",
    "#     return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "wwsrpOik5zhv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = vocab_size,\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vPGmAAXmVLGC",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 300)           26400     \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (64, None, 1024)          1356800   \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (64, None, 1024)          2098176   \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 88)            90200     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,571,576\n",
      "Trainable params: 3,571,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL TRAINING\n",
    "- optimizer & loss function declaration\n",
    "- compilation\n",
    "- epochs number\n",
    "- launching the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4HrXTACTdzY-",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DDl1_Een6rL0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "W6fWTriUZP-n",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints_RNN'        # TODO: remember to choose proper directory\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "7yGBE2zxMMHs",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UK-hmKjYVoll",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-26 22:47:58.536848: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1145534]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-12-26 22:47:58.537178: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1145534]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177/177 [==============================] - 327s 2s/step - loss: 2.5853 - accuracy: 0.3487\n",
      "Epoch 2/20\n",
      "138/177 [======================>.......] - ETA: 1:06 - loss: 1.8529 - accuracy: 0.4769"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS\n",
    "- bulding the model and applying saved weights\n",
    "- text generation function\n",
    "- generate text based on the provided beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "zk2WJ2-XjkGz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "latest_check= tf.train.latest_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "LycQ-ot_jjyu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(latest_check)\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "71xa6jnYVrAN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "WvuwZBX5Ogfd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "\n",
    "  num_generate = 1000\n",
    "  input_eval = [char2index[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "  text_generated = []\n",
    "  scaling = 0.5\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "      predictions = predictions / scaling\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      text_generated.append(index2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(generate_text(model, start_string=u\"Harry killed Ron \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cross_entropy_loss(model, test_sequences):\n",
    "    total_loss = 0\n",
    "    total_steps = 0\n",
    "    \n",
    "    for sequence in test_sequences:\n",
    "        input_seq = sequence[:-1]\n",
    "        target_seq = sequence[1:]\n",
    "        \n",
    "        input_seq = tf.expand_dims(input_seq, 0)\n",
    "        \n",
    "        predictions = model(input_seq)\n",
    "        \n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(target_seq, predictions[0], from_logits=True)\n",
    "        \n",
    "        total_loss += tf.reduce_sum(loss).numpy()\n",
    "        total_steps += len(target_seq)\n",
    "    \n",
    "    avg_loss = total_loss / total_steps\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tutaj można załadować inną część tolkiena albo hobbita\n",
    "first_10_sequences = list(sequences.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_loss = calculate_cross_entropy_loss(model, first_10_sequences)\n",
    "avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = np.exp(avg_loss)\n",
    "perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
